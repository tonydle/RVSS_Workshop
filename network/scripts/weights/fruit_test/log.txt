Net Architecture:
Resnet18Skip(
  (res18_backbone): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (conv2_x): Sequential(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv3_x): Sequential(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv4_x): Sequential(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (conv5_x): Sequential(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (top_conv): Sequential(
    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU()
  )
  (lateral_conv1): Sequential(
    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU()
  )
  (lateral_conv2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU()
  )
  (lateral_conv3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU()
  )
  (segmentation_conv): Sequential(
    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 5, kernel_size=(1, 1), stride=(1, 1))
  )
  (criterion): CrossEntropyLoss()
)
Loss Function: CrossEntropyLoss

===========================================================
==================== Hyper-parameters =====================
n_classes: 4
lr: 0.001
epochs: 40
batch_size: 64
weight_decay: 0.0001
scheduler_step: 5
scheduler_gamma: 0.5
model_dir: weights/fruit_test
load_best: 0
log_freq: 20
dataset_dir: dataset/
===========================================================
============= Epoch 0 | 2021-02-03 21:14:53 ===============
=> Current Lr: 0.001
[0/112]: 1.7540
[20/112]: 0.0513
[40/112]: 0.0531
[60/112]: 0.0425
[80/112]: 0.0293
[100/112]: 0.0304
=> Training Loss: 0.0635, Evaluation Loss 0.0320

============= Epoch 1 | 2021-02-03 21:15:20 ===============
=> Current Lr: 0.001
[0/112]: 0.0318
[20/112]: 0.0223
[40/112]: 0.0293
[60/112]: 0.0241
[80/112]: 0.0310
[100/112]: 0.0322
=> Training Loss: 0.0292, Evaluation Loss 0.0245

============= Epoch 2 | 2021-02-03 21:15:48 ===============
=> Current Lr: 0.001
[0/112]: 0.0266
[20/112]: 0.0195
[40/112]: 0.0207
[60/112]: 0.0267
[80/112]: 0.0208
[100/112]: 0.0206
=> Training Loss: 0.0229, Evaluation Loss 0.0222

============= Epoch 3 | 2021-02-03 21:16:15 ===============
=> Current Lr: 0.001
[0/112]: 0.0235
[20/112]: 0.0206
[40/112]: 0.0186
[60/112]: 0.0198
[80/112]: 0.0167
[100/112]: 0.0150
=> Training Loss: 0.0186, Evaluation Loss 0.0179

============= Epoch 4 | 2021-02-03 21:16:43 ===============
=> Current Lr: 0.001
[0/112]: 0.0136
[20/112]: 0.0108
[40/112]: 0.0177
[60/112]: 0.0171
[80/112]: 0.0171
[100/112]: 0.0167
=> Training Loss: 0.0161, Evaluation Loss 0.0170

============= Epoch 5 | 2021-02-03 21:17:11 ===============
=> Current Lr: 0.0005
[0/112]: 0.0134
[20/112]: 0.0150
[40/112]: 0.0102
[60/112]: 0.0101
[80/112]: 0.0098
[100/112]: 0.0121
=> Training Loss: 0.0123, Evaluation Loss 0.0121

============= Epoch 6 | 2021-02-03 21:17:38 ===============
=> Current Lr: 0.0005
[0/112]: 0.0134
[20/112]: 0.0099
[40/112]: 0.0163
[60/112]: 0.0114
[80/112]: 0.0092
[100/112]: 0.0102
=> Training Loss: 0.0107, Evaluation Loss 0.0151

============= Epoch 7 | 2021-02-03 21:18:06 ===============
=> Current Lr: 0.0005
[0/112]: 0.0124
[20/112]: 0.0112
[40/112]: 0.0089
[60/112]: 0.0089
[80/112]: 0.0089
[100/112]: 0.0098
=> Training Loss: 0.0098, Evaluation Loss 0.0100

============= Epoch 8 | 2021-02-03 21:18:33 ===============
=> Current Lr: 0.0005
[0/112]: 0.0082
[20/112]: 0.0075
[40/112]: 0.0093
[60/112]: 0.0104
[80/112]: 0.0070
[100/112]: 0.0122
=> Training Loss: 0.0093, Evaluation Loss 0.0096

============= Epoch 9 | 2021-02-03 21:19:01 ===============
=> Current Lr: 0.0005
[0/112]: 0.0090
[20/112]: 0.0069
[40/112]: 0.0077
[60/112]: 0.0075
[80/112]: 0.0080
[100/112]: 0.0093
=> Training Loss: 0.0085, Evaluation Loss 0.0101

============= Epoch 10 | 2021-02-03 21:19:28 ==============
=> Current Lr: 0.00025
[0/112]: 0.0094
[20/112]: 0.0123
[40/112]: 0.0121
[60/112]: 0.0065
[80/112]: 0.0074
[100/112]: 0.0052
=> Training Loss: 0.0073, Evaluation Loss 0.0067

============= Epoch 11 | 2021-02-03 21:19:56 ==============
=> Current Lr: 0.00025
[0/112]: 0.0057
[20/112]: 0.0057
[40/112]: 0.0054
[60/112]: 0.0063
[80/112]: 0.0071
[100/112]: 0.0065
=> Training Loss: 0.0066, Evaluation Loss 0.0066

============= Epoch 12 | 2021-02-03 21:20:23 ==============
=> Current Lr: 0.00025
[0/112]: 0.0055
[20/112]: 0.0069
[40/112]: 0.0054
[60/112]: 0.0055
[80/112]: 0.0070
[100/112]: 0.0075
=> Training Loss: 0.0062, Evaluation Loss 0.0069

============= Epoch 13 | 2021-02-03 21:20:51 ==============
=> Current Lr: 0.00025
[0/112]: 0.0082
[20/112]: 0.0053
[40/112]: 0.0052
[60/112]: 0.0060
[80/112]: 0.0067
[100/112]: 0.0073
=> Training Loss: 0.0063, Evaluation Loss 0.0065

============= Epoch 14 | 2021-02-03 21:21:18 ==============
=> Current Lr: 0.00025
[0/112]: 0.0051
[20/112]: 0.0051
[40/112]: 0.0056
[60/112]: 0.0064
[80/112]: 0.0062
[100/112]: 0.0055
=> Training Loss: 0.0062, Evaluation Loss 0.0063

============= Epoch 15 | 2021-02-03 21:21:46 ==============
=> Current Lr: 0.000125
[0/112]: 0.0055
[20/112]: 0.0075
[40/112]: 0.0040
[60/112]: 0.0050
[80/112]: 0.0045
[100/112]: 0.0043
=> Training Loss: 0.0053, Evaluation Loss 0.0055

============= Epoch 16 | 2021-02-03 21:22:14 ==============
=> Current Lr: 0.000125
[0/112]: 0.0047
[20/112]: 0.0054
[40/112]: 0.0054
[60/112]: 0.0045
[80/112]: 0.0038
[100/112]: 0.0063
=> Training Loss: 0.0048, Evaluation Loss 0.0048

============= Epoch 17 | 2021-02-03 21:22:41 ==============
=> Current Lr: 0.000125
[0/112]: 0.0039
[20/112]: 0.0045
[40/112]: 0.0044
[60/112]: 0.0042
[80/112]: 0.0042
[100/112]: 0.0069
=> Training Loss: 0.0048, Evaluation Loss 0.0053

============= Epoch 18 | 2021-02-03 21:23:09 ==============
=> Current Lr: 0.000125
[0/112]: 0.0045
[20/112]: 0.0047
[40/112]: 0.0042
[60/112]: 0.0043
[80/112]: 0.0056
[100/112]: 0.0041
=> Training Loss: 0.0048, Evaluation Loss 0.0073

============= Epoch 19 | 2021-02-03 21:23:36 ==============
=> Current Lr: 0.000125
[0/112]: 0.0048
[20/112]: 0.0051
[40/112]: 0.0055
[60/112]: 0.0049
[80/112]: 0.0048
[100/112]: 0.0044
=> Training Loss: 0.0049, Evaluation Loss 0.0051

============= Epoch 20 | 2021-02-03 21:24:03 ==============
=> Current Lr: 6.25e-05
[0/112]: 0.0032
[20/112]: 0.0052
[40/112]: 0.0032
[60/112]: 0.0044
[80/112]: 0.0044
[100/112]: 0.0036
=> Training Loss: 0.0043, Evaluation Loss 0.0045

============= Epoch 21 | 2021-02-03 21:24:31 ==============
=> Current Lr: 6.25e-05
[0/112]: 0.0034
[20/112]: 0.0035
[40/112]: 0.0043
[60/112]: 0.0037
[80/112]: 0.0038
[100/112]: 0.0033
=> Training Loss: 0.0041, Evaluation Loss 0.0044

============= Epoch 22 | 2021-02-03 21:24:59 ==============
=> Current Lr: 6.25e-05
[0/112]: 0.0047
[20/112]: 0.0033
[40/112]: 0.0035
[60/112]: 0.0052
[80/112]: 0.0045
[100/112]: 0.0039
=> Training Loss: 0.0040, Evaluation Loss 0.0044

============= Epoch 23 | 2021-02-03 21:25:26 ==============
=> Current Lr: 6.25e-05
[0/112]: 0.0035
[20/112]: 0.0042
[40/112]: 0.0041
[60/112]: 0.0040
[80/112]: 0.0045
[100/112]: 0.0041
=> Training Loss: 0.0040, Evaluation Loss 0.0043

============= Epoch 24 | 2021-02-03 21:25:54 ==============
=> Current Lr: 6.25e-05
[0/112]: 0.0040
[20/112]: 0.0042
[40/112]: 0.0034
[60/112]: 0.0047
[80/112]: 0.0047
[100/112]: 0.0041
=> Training Loss: 0.0040, Evaluation Loss 0.0041

============= Epoch 25 | 2021-02-03 21:26:21 ==============
=> Current Lr: 3.125e-05
[0/112]: 0.0034
[20/112]: 0.0037
[40/112]: 0.0037
[60/112]: 0.0032
[80/112]: 0.0029
[100/112]: 0.0037
=> Training Loss: 0.0037, Evaluation Loss 0.0039

============= Epoch 26 | 2021-02-03 21:26:49 ==============
=> Current Lr: 3.125e-05
[0/112]: 0.0031
[20/112]: 0.0036
[40/112]: 0.0035
[60/112]: 0.0034
[80/112]: 0.0029
[100/112]: 0.0043
=> Training Loss: 0.0037, Evaluation Loss 0.0041

============= Epoch 27 | 2021-02-03 21:27:16 ==============
=> Current Lr: 3.125e-05
[0/112]: 0.0039
[20/112]: 0.0038
[40/112]: 0.0030
[60/112]: 0.0031
[80/112]: 0.0049
[100/112]: 0.0037
=> Training Loss: 0.0035, Evaluation Loss 0.0037

============= Epoch 28 | 2021-02-03 21:27:44 ==============
=> Current Lr: 3.125e-05
[0/112]: 0.0037
[20/112]: 0.0032
[40/112]: 0.0033
[60/112]: 0.0028
[80/112]: 0.0036
[100/112]: 0.0032
=> Training Loss: 0.0035, Evaluation Loss 0.0036

============= Epoch 29 | 2021-02-03 21:28:12 ==============
=> Current Lr: 3.125e-05
[0/112]: 0.0042
[20/112]: 0.0026
[40/112]: 0.0038
[60/112]: 0.0034
[80/112]: 0.0045
[100/112]: 0.0040
=> Training Loss: 0.0035, Evaluation Loss 0.0037

============= Epoch 30 | 2021-02-03 21:28:39 ==============
=> Current Lr: 1.5625e-05
[0/112]: 0.0024
[20/112]: 0.0030
[40/112]: 0.0033
[60/112]: 0.0033
[80/112]: 0.0033
[100/112]: 0.0031
=> Training Loss: 0.0033, Evaluation Loss 0.0036

============= Epoch 31 | 2021-02-03 21:29:07 ==============
=> Current Lr: 1.5625e-05
[0/112]: 0.0026
[20/112]: 0.0037
[40/112]: 0.0032
[60/112]: 0.0027
[80/112]: 0.0029
[100/112]: 0.0037
=> Training Loss: 0.0033, Evaluation Loss 0.0036

============= Epoch 32 | 2021-02-03 21:29:35 ==============
=> Current Lr: 1.5625e-05
[0/112]: 0.0029
[20/112]: 0.0031
[40/112]: 0.0036
[60/112]: 0.0028
[80/112]: 0.0031
[100/112]: 0.0032
=> Training Loss: 0.0031, Evaluation Loss 0.0034

============= Epoch 33 | 2021-02-03 21:30:02 ==============
=> Current Lr: 1.5625e-05
[0/112]: 0.0032
[20/112]: 0.0038
[40/112]: 0.0031
[60/112]: 0.0031
[80/112]: 0.0033
[100/112]: 0.0036
=> Training Loss: 0.0032, Evaluation Loss 0.0035

============= Epoch 34 | 2021-02-03 21:30:30 ==============
=> Current Lr: 1.5625e-05
[0/112]: 0.0027
[20/112]: 0.0030
[40/112]: 0.0027
[60/112]: 0.0027
[80/112]: 0.0058
[100/112]: 0.0044
=> Training Loss: 0.0033, Evaluation Loss 0.0035

============= Epoch 35 | 2021-02-03 21:30:57 ==============
=> Current Lr: 7.8125e-06
[0/112]: 0.0029
[20/112]: 0.0031
[40/112]: 0.0028
[60/112]: 0.0031
[80/112]: 0.0031
[100/112]: 0.0032
=> Training Loss: 0.0031, Evaluation Loss 0.0034

============= Epoch 36 | 2021-02-03 21:31:25 ==============
=> Current Lr: 7.8125e-06
[0/112]: 0.0035
[20/112]: 0.0028
[40/112]: 0.0027
[60/112]: 0.0028
[80/112]: 0.0026
[100/112]: 0.0023
=> Training Loss: 0.0032, Evaluation Loss 0.0035

============= Epoch 37 | 2021-02-03 21:31:52 ==============
=> Current Lr: 7.8125e-06
[0/112]: 0.0030
[20/112]: 0.0029
[40/112]: 0.0030
[60/112]: 0.0034
[80/112]: 0.0031
[100/112]: 0.0036
=> Training Loss: 0.0031, Evaluation Loss 0.0034

============= Epoch 38 | 2021-02-03 21:32:19 ==============
=> Current Lr: 7.8125e-06
[0/112]: 0.0022
[20/112]: 0.0034
[40/112]: 0.0029
[60/112]: 0.0032
[80/112]: 0.0040
[100/112]: 0.0034
=> Training Loss: 0.0031, Evaluation Loss 0.0033

============= Epoch 39 | 2021-02-03 21:32:47 ==============
=> Current Lr: 7.8125e-06
[0/112]: 0.0036
[20/112]: 0.0036
[40/112]: 0.0030
[60/112]: 0.0032
[80/112]: 0.0024
[100/112]: 0.0027
=> Training Loss: 0.0030, Evaluation Loss 0.0035

============= Epoch 40 | 2021-02-03 21:39:20 ==============
=> Current Lr: 3.90625e-06
[0/112]: 0.0022
[20/112]: 0.0028
[40/112]: 0.0035
[60/112]: 0.0025
[80/112]: 0.0034
[100/112]: 0.0031
=> Training Loss: 0.0030, Evaluation Loss 0.0033

============= Epoch 41 | 2021-02-03 21:39:48 ==============
=> Current Lr: 3.90625e-06
[0/112]: 0.0034
[20/112]: 0.0035
[40/112]: 0.0029
[60/112]: 0.0028
[80/112]: 0.0032
[100/112]: 0.0029
=> Training Loss: 0.0030, Evaluation Loss 0.0033

============= Epoch 42 | 2021-02-03 21:40:15 ==============
=> Current Lr: 3.90625e-06
[0/112]: 0.0029
[20/112]: 0.0032
[40/112]: 0.0025
[60/112]: 0.0027
[80/112]: 0.0039
[100/112]: 0.0030
=> Training Loss: 0.0030, Evaluation Loss 0.0033

============= Epoch 43 | 2021-02-03 21:40:43 ==============
=> Current Lr: 3.90625e-06
[0/112]: 0.0027
[20/112]: 0.0025
[40/112]: 0.0026
[60/112]: 0.0037
[80/112]: 0.0022
[100/112]: 0.0023
=> Training Loss: 0.0030, Evaluation Loss 0.0033

============= Epoch 44 | 2021-02-03 21:41:10 ==============
=> Current Lr: 3.90625e-06
[0/112]: 0.0028
[20/112]: 0.0027
[40/112]: 0.0028
[60/112]: 0.0026
[80/112]: 0.0030
[100/112]: 0.0031
=> Training Loss: 0.0029, Evaluation Loss 0.0033

============= Epoch 45 | 2021-02-03 21:41:38 ==============
=> Current Lr: 1.953125e-06
[0/112]: 0.0026
[20/112]: 0.0032
[40/112]: 0.0030
[60/112]: 0.0028
[80/112]: 0.0027
[100/112]: 0.0025
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 46 | 2021-02-03 21:42:05 ==============
=> Current Lr: 1.953125e-06
[0/112]: 0.0032
[20/112]: 0.0029
[40/112]: 0.0026
[60/112]: 0.0024
[80/112]: 0.0027
[100/112]: 0.0027
=> Training Loss: 0.0029, Evaluation Loss 0.0033

============= Epoch 47 | 2021-02-03 21:42:33 ==============
=> Current Lr: 1.953125e-06
[0/112]: 0.0030
[20/112]: 0.0032
[40/112]: 0.0027
[60/112]: 0.0038
[80/112]: 0.0028
[100/112]: 0.0029
=> Training Loss: 0.0029, Evaluation Loss 0.0033

============= Epoch 48 | 2021-02-03 21:43:00 ==============
=> Current Lr: 1.953125e-06
[0/112]: 0.0037
[20/112]: 0.0028
[40/112]: 0.0026
[60/112]: 0.0042
[80/112]: 0.0032
[100/112]: 0.0026
=> Training Loss: 0.0030, Evaluation Loss 0.0032

============= Epoch 49 | 2021-02-03 21:43:28 ==============
=> Current Lr: 1.953125e-06
[0/112]: 0.0025
[20/112]: 0.0031
[40/112]: 0.0034
[60/112]: 0.0030
[80/112]: 0.0030
[100/112]: 0.0030
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 50 | 2021-02-03 21:43:56 ==============
=> Current Lr: 9.765625e-07
[0/112]: 0.0028
[20/112]: 0.0024
[40/112]: 0.0028
[60/112]: 0.0027
[80/112]: 0.0032
[100/112]: 0.0023
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 51 | 2021-02-03 21:44:23 ==============
=> Current Lr: 9.765625e-07
[0/112]: 0.0025
[20/112]: 0.0028
[40/112]: 0.0042
[60/112]: 0.0027
[80/112]: 0.0027
[100/112]: 0.0026
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 52 | 2021-02-03 21:44:51 ==============
=> Current Lr: 9.765625e-07
[0/112]: 0.0028
[20/112]: 0.0030
[40/112]: 0.0030
[60/112]: 0.0025
[80/112]: 0.0025
[100/112]: 0.0033
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 53 | 2021-02-03 21:45:18 ==============
=> Current Lr: 9.765625e-07
[0/112]: 0.0033
[20/112]: 0.0034
[40/112]: 0.0027
[60/112]: 0.0027
[80/112]: 0.0022
[100/112]: 0.0033
=> Training Loss: 0.0029, Evaluation Loss 0.0034

============= Epoch 54 | 2021-02-03 21:45:45 ==============
=> Current Lr: 9.765625e-07
[0/112]: 0.0029
[20/112]: 0.0037
[40/112]: 0.0029
[60/112]: 0.0029
[80/112]: 0.0028
[100/112]: 0.0037
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 55 | 2021-02-03 21:46:13 ==============
=> Current Lr: 4.8828125e-07
[0/112]: 0.0027
[20/112]: 0.0022
[40/112]: 0.0026
[60/112]: 0.0030
[80/112]: 0.0032
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 56 | 2021-02-03 21:46:40 ==============
=> Current Lr: 4.8828125e-07
[0/112]: 0.0031
[20/112]: 0.0030
[40/112]: 0.0024
[60/112]: 0.0032
[80/112]: 0.0025
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 57 | 2021-02-03 21:47:08 ==============
=> Current Lr: 4.8828125e-07
[0/112]: 0.0028
[20/112]: 0.0026
[40/112]: 0.0030
[60/112]: 0.0030
[80/112]: 0.0028
[100/112]: 0.0031
=> Training Loss: 0.0028, Evaluation Loss 0.0034

============= Epoch 58 | 2021-02-03 21:47:35 ==============
=> Current Lr: 4.8828125e-07
[0/112]: 0.0025
[20/112]: 0.0025
[40/112]: 0.0030
[60/112]: 0.0029
[80/112]: 0.0029
[100/112]: 0.0029
=> Training Loss: 0.0029, Evaluation Loss 0.0033

============= Epoch 59 | 2021-02-03 21:48:03 ==============
=> Current Lr: 4.8828125e-07
[0/112]: 0.0029
[20/112]: 0.0039
[40/112]: 0.0025
[60/112]: 0.0033
[80/112]: 0.0029
[100/112]: 0.0031
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 60 | 2021-02-03 21:48:30 ==============
=> Current Lr: 2.44140625e-07
[0/112]: 0.0029
[20/112]: 0.0030
[40/112]: 0.0027
[60/112]: 0.0027
[80/112]: 0.0028
[100/112]: 0.0025
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 61 | 2021-02-03 21:48:57 ==============
=> Current Lr: 2.44140625e-07
[0/112]: 0.0033
[20/112]: 0.0026
[40/112]: 0.0029
[60/112]: 0.0025
[80/112]: 0.0027
[100/112]: 0.0039
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 62 | 2021-02-03 21:49:25 ==============
=> Current Lr: 2.44140625e-07
[0/112]: 0.0028
[20/112]: 0.0029
[40/112]: 0.0024
[60/112]: 0.0029
[80/112]: 0.0026
[100/112]: 0.0032
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 63 | 2021-02-03 21:49:52 ==============
=> Current Lr: 2.44140625e-07
[0/112]: 0.0024
[20/112]: 0.0023
[40/112]: 0.0031
[60/112]: 0.0029
[80/112]: 0.0029
[100/112]: 0.0024
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 64 | 2021-02-03 21:50:20 ==============
=> Current Lr: 2.44140625e-07
[0/112]: 0.0028
[20/112]: 0.0027
[40/112]: 0.0025
[60/112]: 0.0026
[80/112]: 0.0030
[100/112]: 0.0026
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 65 | 2021-02-03 21:50:47 ==============
=> Current Lr: 1.220703125e-07
[0/112]: 0.0028
[20/112]: 0.0022
[40/112]: 0.0024
[60/112]: 0.0039
[80/112]: 0.0025
[100/112]: 0.0031
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 66 | 2021-02-03 21:51:15 ==============
=> Current Lr: 1.220703125e-07
[0/112]: 0.0028
[20/112]: 0.0033
[40/112]: 0.0026
[60/112]: 0.0028
[80/112]: 0.0032
[100/112]: 0.0032
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 67 | 2021-02-03 21:51:42 ==============
=> Current Lr: 1.220703125e-07
[0/112]: 0.0025
[20/112]: 0.0029
[40/112]: 0.0026
[60/112]: 0.0025
[80/112]: 0.0027
[100/112]: 0.0032
=> Training Loss: 0.0029, Evaluation Loss 0.0030

============= Epoch 68 | 2021-02-03 21:52:09 ==============
=> Current Lr: 1.220703125e-07
[0/112]: 0.0029
[20/112]: 0.0036
[40/112]: 0.0028
[60/112]: 0.0028
[80/112]: 0.0037
[100/112]: 0.0029
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 69 | 2021-02-03 21:52:37 ==============
=> Current Lr: 1.220703125e-07
[0/112]: 0.0027
[20/112]: 0.0032
[40/112]: 0.0028
[60/112]: 0.0040
[80/112]: 0.0031
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 70 | 2021-02-03 21:53:04 ==============
=> Current Lr: 6.103515625e-08
[0/112]: 0.0025
[20/112]: 0.0030
[40/112]: 0.0028
[60/112]: 0.0028
[80/112]: 0.0030
[100/112]: 0.0034
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 71 | 2021-02-03 21:53:32 ==============
=> Current Lr: 6.103515625e-08
[0/112]: 0.0025
[20/112]: 0.0027
[40/112]: 0.0023
[60/112]: 0.0034
[80/112]: 0.0026
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 72 | 2021-02-03 21:53:59 ==============
=> Current Lr: 6.103515625e-08
[0/112]: 0.0026
[20/112]: 0.0032
[40/112]: 0.0036
[60/112]: 0.0030
[80/112]: 0.0026
[100/112]: 0.0043
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 73 | 2021-02-03 21:54:27 ==============
=> Current Lr: 6.103515625e-08
[0/112]: 0.0026
[20/112]: 0.0031
[40/112]: 0.0029
[60/112]: 0.0032
[80/112]: 0.0028
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 74 | 2021-02-03 21:54:54 ==============
=> Current Lr: 6.103515625e-08
[0/112]: 0.0024
[20/112]: 0.0032
[40/112]: 0.0029
[60/112]: 0.0030
[80/112]: 0.0027
[100/112]: 0.0023
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 75 | 2021-02-03 21:55:21 ==============
=> Current Lr: 3.0517578125e-08
[0/112]: 0.0025
[20/112]: 0.0031
[40/112]: 0.0034
[60/112]: 0.0025
[80/112]: 0.0035
[100/112]: 0.0024
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 76 | 2021-02-03 21:55:49 ==============
=> Current Lr: 3.0517578125e-08
[0/112]: 0.0026
[20/112]: 0.0028
[40/112]: 0.0034
[60/112]: 0.0028
[80/112]: 0.0043
[100/112]: 0.0024
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 77 | 2021-02-03 21:56:17 ==============
=> Current Lr: 3.0517578125e-08
[0/112]: 0.0027
[20/112]: 0.0028
[40/112]: 0.0035
[60/112]: 0.0031
[80/112]: 0.0039
[100/112]: 0.0029
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 78 | 2021-02-03 21:56:44 ==============
=> Current Lr: 3.0517578125e-08
[0/112]: 0.0031
[20/112]: 0.0028
[40/112]: 0.0029
[60/112]: 0.0028
[80/112]: 0.0030
[100/112]: 0.0029
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 79 | 2021-02-03 21:57:11 ==============
=> Current Lr: 3.0517578125e-08
[0/112]: 0.0029
[20/112]: 0.0032
[40/112]: 0.0034
[60/112]: 0.0023
[80/112]: 0.0024
[100/112]: 0.0030
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 80 | 2021-02-03 21:57:39 ==============
=> Current Lr: 1.52587890625e-08
[0/112]: 0.0022
[20/112]: 0.0025
[40/112]: 0.0034
[60/112]: 0.0031
[80/112]: 0.0034
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 81 | 2021-02-03 21:58:06 ==============
=> Current Lr: 1.52587890625e-08
[0/112]: 0.0027
[20/112]: 0.0027
[40/112]: 0.0032
[60/112]: 0.0033
[80/112]: 0.0028
[100/112]: 0.0026
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 82 | 2021-02-03 21:58:34 ==============
=> Current Lr: 1.52587890625e-08
[0/112]: 0.0026
[20/112]: 0.0031
[40/112]: 0.0025
[60/112]: 0.0031
[80/112]: 0.0029
[100/112]: 0.0023
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 83 | 2021-02-03 21:59:01 ==============
=> Current Lr: 1.52587890625e-08
[0/112]: 0.0028
[20/112]: 0.0027
[40/112]: 0.0029
[60/112]: 0.0030
[80/112]: 0.0025
[100/112]: 0.0033
=> Training Loss: 0.0029, Evaluation Loss 0.0032

============= Epoch 84 | 2021-02-03 21:59:28 ==============
=> Current Lr: 1.52587890625e-08
[0/112]: 0.0033
[20/112]: 0.0036
[40/112]: 0.0028
[60/112]: 0.0027
[80/112]: 0.0023
[100/112]: 0.0028
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 85 | 2021-02-03 21:59:56 ==============
=> Current Lr: 7.62939453125e-09
[0/112]: 0.0028
[20/112]: 0.0026
[40/112]: 0.0028
[60/112]: 0.0025
[80/112]: 0.0029
[100/112]: 0.0036
=> Training Loss: 0.0028, Evaluation Loss 0.0034

============= Epoch 86 | 2021-02-03 22:00:23 ==============
=> Current Lr: 7.62939453125e-09
[0/112]: 0.0040
[20/112]: 0.0032
[40/112]: 0.0025
[60/112]: 0.0033
[80/112]: 0.0024
[100/112]: 0.0020
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 87 | 2021-02-03 22:00:51 ==============
=> Current Lr: 7.62939453125e-09
[0/112]: 0.0027
[20/112]: 0.0028
[40/112]: 0.0025
[60/112]: 0.0025
[80/112]: 0.0026
[100/112]: 0.0034
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 88 | 2021-02-03 22:01:18 ==============
=> Current Lr: 7.62939453125e-09
[0/112]: 0.0029
[20/112]: 0.0035
[40/112]: 0.0031
[60/112]: 0.0034
[80/112]: 0.0032
[100/112]: 0.0028
=> Training Loss: 0.0029, Evaluation Loss 0.0033

============= Epoch 89 | 2021-02-03 22:01:46 ==============
=> Current Lr: 7.62939453125e-09
[0/112]: 0.0025
[20/112]: 0.0027
[40/112]: 0.0026
[60/112]: 0.0033
[80/112]: 0.0024
[100/112]: 0.0022
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 90 | 2021-02-03 22:02:13 ==============
=> Current Lr: 3.814697265625e-09
[0/112]: 0.0026
[20/112]: 0.0026
[40/112]: 0.0027
[60/112]: 0.0031
[80/112]: 0.0037
[100/112]: 0.0022
=> Training Loss: 0.0028, Evaluation Loss 0.0031

============= Epoch 91 | 2021-02-03 22:02:40 ==============
=> Current Lr: 3.814697265625e-09
[0/112]: 0.0032
[20/112]: 0.0031
[40/112]: 0.0029
[60/112]: 0.0032
[80/112]: 0.0027
[100/112]: 0.0027
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 92 | 2021-02-03 22:03:08 ==============
=> Current Lr: 3.814697265625e-09
[0/112]: 0.0037
[20/112]: 0.0027
[40/112]: 0.0030
[60/112]: 0.0022
[80/112]: 0.0025
[100/112]: 0.0028
=> Training Loss: 0.0029, Evaluation Loss 0.0034

============= Epoch 93 | 2021-02-03 22:03:35 ==============
=> Current Lr: 3.814697265625e-09
[0/112]: 0.0034
[20/112]: 0.0027
[40/112]: 0.0034
[60/112]: 0.0022
[80/112]: 0.0035
[100/112]: 0.0024
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 94 | 2021-02-03 22:04:03 ==============
=> Current Lr: 3.814697265625e-09
[0/112]: 0.0027
[20/112]: 0.0031
[40/112]: 0.0024
[60/112]: 0.0037
[80/112]: 0.0026
[100/112]: 0.0023
=> Training Loss: 0.0028, Evaluation Loss 0.0032

============= Epoch 95 | 2021-02-03 22:04:30 ==============
=> Current Lr: 1.9073486328125e-09
[0/112]: 0.0030
[20/112]: 0.0031
[40/112]: 0.0028
[60/112]: 0.0033
[80/112]: 0.0029
[100/112]: 0.0024
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 96 | 2021-02-03 22:04:57 ==============
=> Current Lr: 1.9073486328125e-09
[0/112]: 0.0028
[20/112]: 0.0025
[40/112]: 0.0032
[60/112]: 0.0026
[80/112]: 0.0048
[100/112]: 0.0028
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 97 | 2021-02-03 22:05:25 ==============
=> Current Lr: 1.9073486328125e-09
[0/112]: 0.0024
[20/112]: 0.0030
[40/112]: 0.0028
[60/112]: 0.0036
[80/112]: 0.0033
[100/112]: 0.0030
=> Training Loss: 0.0028, Evaluation Loss 0.0033

============= Epoch 98 | 2021-02-03 22:05:52 ==============
=> Current Lr: 1.9073486328125e-09
[0/112]: 0.0025
[20/112]: 0.0025
[40/112]: 0.0028
[60/112]: 0.0025
[80/112]: 0.0026
[100/112]: 0.0027
=> Training Loss: 0.0029, Evaluation Loss 0.0031

============= Epoch 99 | 2021-02-03 22:06:20 ==============
=> Current Lr: 1.9073486328125e-09
[0/112]: 0.0026
[20/112]: 0.0028
[40/112]: 0.0031
[60/112]: 0.0031
[80/112]: 0.0029
[100/112]: 0.0032
=> Training Loss: 0.0028, Evaluation Loss 0.0034
